{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "from torchvision.transforms.transforms import ToTensor\n",
    "\n",
    "from models.model import My_siamese\n",
    "from utils.utils import increment_path\n",
    "from pathlib import Path\n",
    "\n",
    "from tqdm import tqdm\n",
    "import wandb\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from dataset.reconstruct import prepare_data\n",
    "from dataset.loader import train_validation_loader\n",
    "from dataset.loader import testset_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset Omniglot\n",
       "    Number of datapoints: 0\n",
       "    Root location: data/omniglot-py\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "net = My_siamese().cuda()\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.0005)\n",
    "\n",
    "data_dir = os.path.join(\"data\")\n",
    "datasets.Omniglot(data_dir, background=True, download=True, transform=ToTensor())\n",
    "datasets.Omniglot(data_dir, background=False, download=True, transform=ToTensor())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir, val_dir, test_dir = prepare_data(data_dir)\n",
    "train_loader, val_loader = train_validation_loader(train_dir, val_dir, 8, False, 5, True, 3, 8)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.train()\n",
    "train_loss = 0\n",
    "\n",
    "for i, (img1, img2, label) in tqdm(enumerate(train_loader), total=len(train_loader)):\n",
    "\n",
    "    output = net(img1.cuda(), img2.cuda())\n",
    "    loss = loss_fn(output, label.cuda())\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    train_loss += loss\n",
    "\n",
    "    if (i+1) % (len(train_loader)//5) == 0 or i == (len(train_loader) -1):\n",
    "        # wandb.log({\"Train_loss\":train_loss/i})\n",
    "        print(\"Train_loss\", train_loss/i})\n",
    "\n",
    "train_loss /= len(train_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3b37dd87958159f351f9aa495d9e283d37dc0d2b6a9ade28b1dd9884a16ed8b6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('track': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
