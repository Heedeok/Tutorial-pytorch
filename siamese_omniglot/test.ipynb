{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "from torchvision.transforms.transforms import ToTensor\n",
    "\n",
    "from models.model import My_siamese\n",
    "from utils.utils import increment_path\n",
    "from pathlib import Path\n",
    "\n",
    "from tqdm import tqdm\n",
    "import wandb\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from dataset.reconstruct import prepare_data\n",
    "from dataset.loader import train_validation_loader\n",
    "from dataset.loader import testset_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset Omniglot\n",
       "    Number of datapoints: 0\n",
       "    Root location: data/omniglot-py\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "net = My_siamese().cuda()\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.0005)\n",
    "\n",
    "data_dir = os.path.join(\"data\")\n",
    "datasets.Omniglot(data_dir, background=True, download=True, transform=ToTensor())\n",
    "datasets.Omniglot(data_dir, background=False, download=True, transform=ToTensor())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir, val_dir, test_dir = prepare_data(data_dir, 3)\n",
    "train_loader, val_loader = train_validation_loader(train_dir, val_dir, 8, False, 5, True, 3, 2)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 490/2445 [00:46<03:05, 10.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_loss tensor(0.4583, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 979/2445 [01:34<02:20, 10.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_loss tensor(0.4336, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 1468/2445 [02:21<01:36, 10.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_loss tensor(0.4154, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 1958/2445 [03:07<00:46, 10.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_loss tensor(0.3994, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2445/2445 [03:55<00:00, 10.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_loss tensor(0.3832, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Train_loss tensor(0.3830, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "net.train()\n",
    "train_loss = 0\n",
    "sig = nn.Sigmoid()\n",
    "\n",
    "for i, (img1, img2, label) in tqdm(enumerate(train_loader), total=len(train_loader)):\n",
    "\n",
    "    output = net(img1.cuda(), img2.cuda())\n",
    "    loss = loss_fn(output, label.cuda())\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    train_loss += loss\n",
    "\n",
    "    if (i+1) % (len(train_loader)//5) == 0 or i == (len(train_loader) -1):\n",
    "        # wandb.log({\"Train_loss\":train_loss/i})\n",
    "        print(\"Train_loss\", train_loss/i)\n",
    "\n",
    "train_loss /= len(train_loader)\n",
    "print(\"Train_loss\", train_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load = torch.load(\"./test.pt\")\n",
    "net.load_state_dict(load[\"model\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2445 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "show img :  torch.Size([6, 1, 105, 105])\n",
      "similarity :  tensor([[ 1.5764],\n",
      "        [ 0.6041],\n",
      "        [ 1.0594],\n",
      "        [-1.2201],\n",
      "        [ 1.7759]], device='cuda:0')\n",
      "label :  tensor([[1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]])\n",
      "Val tensor(0.0007, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "net.eval()\n",
    "val_loss = 0\n",
    "\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "with torch.no_grad():    \n",
    "    for i, (img1, img2, label) in tqdm(enumerate(val_loader), total=len(train_loader)):\n",
    "\n",
    "        output = net(img1.cuda(), img2.cuda())\n",
    "        loss = loss_fn(output, label.cuda())\n",
    "\n",
    "        val_loss += loss\n",
    "\n",
    "        if (i+1) % (len(val_loader)//5) == 0 or i == (len(val_loader) -1):\n",
    "            # wandb.log({\"Train_loss\":train_loss/i})\n",
    "            print(\"Val loss\", val_loss/i)\n",
    "\n",
    "        if i==0:\n",
    "            \n",
    "            show_img = torch.cat((img1[0].unsqueeze(0),img2[:5]))\n",
    "            print(\"show img : \", show_img.shape)\n",
    "            similarity = output\n",
    "            print(\"similarity : \", similarity)\n",
    "            print(\"label : \", label)\n",
    "\n",
    "            f_img = torch_to_cv2(show_img)\n",
    "            cv2.imwrite(\"./test2.jpg\", f_img)\n",
    "            s_img = put_result(f_img, similarity, label, 5)\n",
    "            cv2.imwrite(\"./test3.jpg\", s_img)\n",
    "\n",
    "            break\n",
    "\n",
    "    val_loss /= len(val_loader)\n",
    "    print(\"Val\", val_loss)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt = {'model':net.state_dict(),\n",
    "                    'optimizer':optimizer.state_dict(),}\n",
    "torch.save(ckpt, \"./test.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def torch_to_cv2(imgs):\n",
    "\n",
    "    for i, img in enumerate(imgs):\n",
    "\n",
    "        img = img.cpu()\n",
    "        img = img.numpy().transpose(1,2,0)\n",
    "        img = (img -img.min())/(img.max()-img.min())*255\n",
    "\n",
    "        if i ==0:\n",
    "            cv_img = img\n",
    "        else : \n",
    "            cv_img = np.concatenate((cv_img, img), axis=1)\n",
    "\n",
    "    return cv_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def put_result(img, similar, label, candi):\n",
    "\n",
    "    split = candi + 1\n",
    "\n",
    "    w = img.shape[1]//split\n",
    "\n",
    "    for i in range(split):\n",
    "        \n",
    "        if i ==0:\n",
    "            cv2.putText(img, \"Template\", (w//4, 15), cv2.FONT_HERSHEY_SIMPLEX, 0.4, 0,2)\n",
    "        else : \n",
    "            s = similar[i-1].item()\n",
    "            l = int(label[i-1].item())\n",
    "            cv2.putText(img, f\"Result : {s:.2f}\", (w//9 + w*i, 100), cv2.FONT_HERSHEY_SIMPLEX, 0.4, 0,2)\n",
    "            cv2.putText(img, f\"Label : {int(l)}\", (w//4 + w*i, 15), cv2.FONT_HERSHEY_SIMPLEX, 0.4, 0,2)\n",
    "\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2445 [00:00<?, ?it/s]Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f4450cc59d0>\n",
      "Traceback (most recent call last):\n",
      "Exception ignored in:   File \"/home/jwk6844/anaconda3/envs/track/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7f4450cc59d0>    \n",
      "self._shutdown_workers()Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/jwk6844/anaconda3/envs/track/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
      "  File \"/home/jwk6844/anaconda3/envs/track/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "        if w.is_alive():self._shutdown_workers()\n",
      "\n",
      "  File \"/home/jwk6844/anaconda3/envs/track/lib/python3.8/multiprocessing/process.py\", line 160, in is_alive\n",
      "  File \"/home/jwk6844/anaconda3/envs/track/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
      "        if w.is_alive():assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "\n",
      "AssertionError  File \"/home/jwk6844/anaconda3/envs/track/lib/python3.8/multiprocessing/process.py\", line 160, in is_alive\n",
      ": can only test a child process    \n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "  0%|          | 0/2445 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "show img :  torch.Size([6, 1, 105, 105])\n",
      "similarity :  tensor([[ 1.9571],\n",
      "        [-3.1557],\n",
      "        [ 0.1665],\n",
      "        [-2.1002],\n",
      "        [-1.1059]], device='cuda:0')\n",
      "label :  tensor([[1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]])\n",
      "Val tensor(0.0002, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_loader = testset_loader(test_dir, 5, 3, 2)\n",
    "    \n",
    "\n",
    "\n",
    "with torch.no_grad():    \n",
    "    for i, (img1, img2, label) in tqdm(enumerate(test_loader), total=len(train_loader)):\n",
    "\n",
    "        output = net(img1.cuda(), img2.cuda())\n",
    "        loss = loss_fn(output, label.cuda())\n",
    "\n",
    "        val_loss += loss\n",
    "\n",
    "        if (i+1) % (len(test_loader)//5) == 0 or i == (len(test_loader) -1):\n",
    "            # wandb.log({\"Train_loss\":train_loss/i})\n",
    "            print(\"Val loss\", val_loss/i)\n",
    "\n",
    "        if i==0:\n",
    "            \n",
    "            show_img = torch.cat((img1[0].unsqueeze(0),img2[:5]))\n",
    "            print(\"show img : \", show_img.shape)\n",
    "            similarity = output\n",
    "            print(\"similarity : \", similarity)\n",
    "            print(\"label : \", label)\n",
    "\n",
    "            f_img = torch_to_cv2(show_img)\n",
    "            cv2.imwrite(\"./test_2.jpg\", f_img)\n",
    "            s_img = put_result(f_img, similarity, label, 5)\n",
    "            cv2.imwrite(\"./test_3.jpg\", s_img)\n",
    "\n",
    "            break\n",
    "\n",
    "    val_loss /= len(test_loader)\n",
    "    print(\"Val\", val_loss)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "97f79c95c27a14819227b3b48108457daf78295b1f64d5e04ef8365cb73493b3"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('track': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
